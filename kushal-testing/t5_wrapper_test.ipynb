{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llmfoundry.models.hf import ComposerHFT5\n",
    "import torch\n",
    "from transformers import T5Tokenizer, AutoTokenizer, T5TokenizerFast, PreTrainedTokenizerFast, AutoConfig\n",
    "from chronos.chronos import ChronosConfig, ChronosTokenizer, ChronosModel, MeanScaleUniformBins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/amazon-science/chronos-forecasting.git\n",
      "  Cloning https://github.com/amazon-science/chronos-forecasting.git to /tmp/pip-req-build-kst7mi0l\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/amazon-science/chronos-forecasting.git /tmp/pip-req-build-kst7mi0l\n",
      "  Resolved https://github.com/amazon-science/chronos-forecasting.git to commit d2e0c9d6d57878ebf5af62c1ad3a12b2eb52175a\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch~=2.0 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from chronos==1.2.0) (2.3.1)\n",
      "Requirement already satisfied: transformers~=4.30 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from chronos==1.2.0) (4.40.2)\n",
      "Requirement already satisfied: accelerate in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from chronos==1.2.0) (0.25.0)\n",
      "Requirement already satisfied: filelock in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from torch~=2.0->chronos==1.2.0) (3.15.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from torch~=2.0->chronos==1.2.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from torch~=2.0->chronos==1.2.0) (1.12.1)\n",
      "Requirement already satisfied: networkx in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from torch~=2.0->chronos==1.2.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from torch~=2.0->chronos==1.2.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from torch~=2.0->chronos==1.2.0) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from torch~=2.0->chronos==1.2.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from torch~=2.0->chronos==1.2.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from torch~=2.0->chronos==1.2.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from torch~=2.0->chronos==1.2.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from torch~=2.0->chronos==1.2.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from torch~=2.0->chronos==1.2.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from torch~=2.0->chronos==1.2.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from torch~=2.0->chronos==1.2.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from torch~=2.0->chronos==1.2.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from torch~=2.0->chronos==1.2.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from torch~=2.0->chronos==1.2.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from torch~=2.0->chronos==1.2.0) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch~=2.0->chronos==1.2.0) (12.5.40)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from transformers~=4.30->chronos==1.2.0) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from transformers~=4.30->chronos==1.2.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from transformers~=4.30->chronos==1.2.0) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from transformers~=4.30->chronos==1.2.0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from transformers~=4.30->chronos==1.2.0) (2024.5.15)\n",
      "Requirement already satisfied: requests in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from transformers~=4.30->chronos==1.2.0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from transformers~=4.30->chronos==1.2.0) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from transformers~=4.30->chronos==1.2.0) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from transformers~=4.30->chronos==1.2.0) (4.66.4)\n",
      "Requirement already satisfied: psutil in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from accelerate->chronos==1.2.0) (5.9.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from jinja2->torch~=2.0->chronos==1.2.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from requests->transformers~=4.30->chronos==1.2.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from requests->transformers~=4.30->chronos==1.2.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from requests->transformers~=4.30->chronos==1.2.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from requests->transformers~=4.30->chronos==1.2.0) (2024.6.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages (from sympy->torch~=2.0->chronos==1.2.0) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/amazon-science/chronos-forecasting.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/mnt/workdisk/kushal/llm-foundry/llmfoundry/utils/warnings.py:89: ExperimentalWarning: ComposerHFT5 is experimental and may change with future versions.\n",
      "  warnings.warn(ExperimentalWarning(feature_name))\n",
      "/usr/lib/python3/dist-packages/transformers/models/auto/configuration_auto.py:913: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = ComposerHFT5(tokenizer = T5Tokenizer.from_pretrained(\"google-t5/t5-small\"), # PreTrainedTokenizerBase\n",
    "        pretrained_model_name_or_path = 'google-t5/t5-small', # str\n",
    "        pretrained = True, # Optional[bool] = True\n",
    "        trust_remote_code = True, # bool = True\n",
    "        use_auth_token = False, # bool = False\n",
    "        config_overrides = None, # Optional[Mapping] = None\n",
    "        init_device = 'cpu', # str = 'cpu'\n",
    "        additional_train_metrics = None, # Optional[List] = None\n",
    "        name = 't5-small', #: Optional[str] = None\n",
    ")\n",
    "# tokenizer: https://huggingface.co/docs/transformers/en/model_doc/t5#transformers.T5Tokenizer\n",
    "# pretrained model: https://huggingface.co/google-t5/t5-small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing model keys with `torch.load()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = torch.load('/mnt/workdisk/kushal/llm-foundry/scripts/output/t5-small-interactive-MWt1uQ/ep0-ba5-rank0.pt')\n",
    "model_10 = torch.load('/mnt/workdisk/kushal/llm-foundry/scripts/output/t5-small-interactive-MWt1uQ/ep0-ba10-rank0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['state', 'rng'])\n",
      "dict_keys(['state', 'rng'])\n"
     ]
    }
   ],
   "source": [
    "print(model_5.keys())\n",
    "print(model_10.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model', 'optimizers', 'schedulers', 'algorithms', 'callbacks', 'scaler', 'timestamp', 'rank_zero_seed', 'run_name', 'dataset_state', 'integrations', 'metadata'])\n",
      "dict_keys(['model', 'optimizers', 'schedulers', 'algorithms', 'callbacks', 'scaler', 'timestamp', 'rank_zero_seed', 'run_name', 'dataset_state', 'integrations', 'metadata'])\n"
     ]
    }
   ],
   "source": [
    "print(model_5['state'].keys())\n",
    "print(model_10['state'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -2.0156,   0.2237,  -7.0937,  ...,  -0.3535,   2.6407,  -2.8907],\n",
      "        [ 12.6250,   8.1875, -11.6250,  ...,   7.9375,  -7.3125,   0.9454],\n",
      "        [ -8.7500,   7.1875,  27.8750,  ..., -26.7500,   0.8554,  -1.5157],\n",
      "        ...,\n",
      "        [-25.2500, -28.5000, -17.2500,  ..., -17.7500,  -5.2500,  27.3750],\n",
      "        [-25.5000, -29.3750, -18.2500,  ..., -17.7500,  -4.8125,  27.7500],\n",
      "        [-26.7500, -28.3750, -17.8750,  ..., -18.5000,  -7.0000,  27.6250]],\n",
      "       device='cuda:0')\n",
      "tensor([[ -2.0156,   0.2237,  -7.0937,  ...,  -0.3535,   2.6407,  -2.8907],\n",
      "        [ 12.6249,   8.1874, -11.6249,  ...,   7.9374,  -7.3125,   0.9454],\n",
      "        [ -8.7500,   7.1875,  27.8750,  ..., -26.7500,   0.8554,  -1.5157],\n",
      "        ...,\n",
      "        [-25.2500, -28.5000, -17.2500,  ..., -17.7500,  -5.2500,  27.3750],\n",
      "        [-25.5000, -29.3750, -18.2500,  ..., -17.7500,  -4.8125,  27.7500],\n",
      "        [-26.7500, -28.3750, -17.8750,  ..., -18.5000,  -7.0000,  27.6250]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model_5['state']['model']['model.lm_head.weight'])\n",
    "print(model_10['state']['model']['model.lm_head.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['python', 'numpy', 'torch', 'cuda'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['rng'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " (2147483648,\n",
       "  3170634271,\n",
       "  2035982193,\n",
       "  859452641,\n",
       "  567914427,\n",
       "  1526164465,\n",
       "  2652430106,\n",
       "  3549929089,\n",
       "  15118359,\n",
       "  3474503331,\n",
       "  2204943320,\n",
       "  561448987,\n",
       "  3853569459,\n",
       "  2672065287,\n",
       "  1054713599,\n",
       "  1216758441,\n",
       "  120103628,\n",
       "  4113501092,\n",
       "  75122332,\n",
       "  3635752974,\n",
       "  2922626534,\n",
       "  3504939389,\n",
       "  4262355907,\n",
       "  2016019026,\n",
       "  3786930039,\n",
       "  3546084902,\n",
       "  2881831452,\n",
       "  3911063105,\n",
       "  57826278,\n",
       "  1556482840,\n",
       "  3416069416,\n",
       "  412658993,\n",
       "  579477156,\n",
       "  3541357095,\n",
       "  1351528459,\n",
       "  1468409607,\n",
       "  3336715696,\n",
       "  4213747970,\n",
       "  279014888,\n",
       "  4252844498,\n",
       "  2849747261,\n",
       "  3989422257,\n",
       "  1944182354,\n",
       "  275339130,\n",
       "  2315189997,\n",
       "  1571994218,\n",
       "  3156519093,\n",
       "  1534727095,\n",
       "  3185519333,\n",
       "  1646492138,\n",
       "  3720201960,\n",
       "  2751641298,\n",
       "  3708784016,\n",
       "  2709587081,\n",
       "  152700890,\n",
       "  3997662882,\n",
       "  3047081649,\n",
       "  591435452,\n",
       "  3678047174,\n",
       "  3538079613,\n",
       "  3298226431,\n",
       "  3141372844,\n",
       "  3578240196,\n",
       "  3027385354,\n",
       "  836073235,\n",
       "  872312709,\n",
       "  1897193585,\n",
       "  1148545581,\n",
       "  836544537,\n",
       "  579720199,\n",
       "  237082603,\n",
       "  2065715651,\n",
       "  1231944690,\n",
       "  796029371,\n",
       "  2910745831,\n",
       "  2515041565,\n",
       "  3738523080,\n",
       "  2842675705,\n",
       "  764172881,\n",
       "  2508376986,\n",
       "  3528772597,\n",
       "  2897577845,\n",
       "  1856424615,\n",
       "  3893117235,\n",
       "  3673901576,\n",
       "  2645330135,\n",
       "  554700591,\n",
       "  1262309979,\n",
       "  2259525681,\n",
       "  2431938713,\n",
       "  2786353094,\n",
       "  1800114801,\n",
       "  108467547,\n",
       "  4263541717,\n",
       "  3144381904,\n",
       "  228239006,\n",
       "  3607132046,\n",
       "  331128244,\n",
       "  1007168535,\n",
       "  2004307575,\n",
       "  2118205155,\n",
       "  2613370894,\n",
       "  1358553355,\n",
       "  2246604741,\n",
       "  828456630,\n",
       "  2409983598,\n",
       "  2726550797,\n",
       "  110116450,\n",
       "  4177904623,\n",
       "  3602439421,\n",
       "  425907334,\n",
       "  2119587308,\n",
       "  4027373549,\n",
       "  1835051528,\n",
       "  2270949822,\n",
       "  2898424876,\n",
       "  276903548,\n",
       "  3980885543,\n",
       "  302055370,\n",
       "  2840683264,\n",
       "  2065579340,\n",
       "  4000132080,\n",
       "  2960491564,\n",
       "  1093934736,\n",
       "  98130282,\n",
       "  3105950189,\n",
       "  1493640476,\n",
       "  1902084372,\n",
       "  1306367855,\n",
       "  3813332714,\n",
       "  102617506,\n",
       "  430103636,\n",
       "  3370257020,\n",
       "  4192105938,\n",
       "  782769412,\n",
       "  1683258357,\n",
       "  3874318333,\n",
       "  2284334076,\n",
       "  3169046626,\n",
       "  3121370183,\n",
       "  2342946363,\n",
       "  2968180184,\n",
       "  1719901354,\n",
       "  1539747387,\n",
       "  253169846,\n",
       "  1244388748,\n",
       "  3747092065,\n",
       "  2303341562,\n",
       "  829832046,\n",
       "  494955251,\n",
       "  2848526053,\n",
       "  1164900090,\n",
       "  3968752284,\n",
       "  3061004553,\n",
       "  2110524080,\n",
       "  551819962,\n",
       "  3325797028,\n",
       "  2923321116,\n",
       "  2303723165,\n",
       "  3532309000,\n",
       "  3803111310,\n",
       "  4209296353,\n",
       "  1554836982,\n",
       "  135161885,\n",
       "  1776633805,\n",
       "  1343620534,\n",
       "  2934692533,\n",
       "  197440650,\n",
       "  462012486,\n",
       "  2799860832,\n",
       "  2856315324,\n",
       "  1493458078,\n",
       "  3543399439,\n",
       "  64612389,\n",
       "  2650906115,\n",
       "  3885998626,\n",
       "  2496280281,\n",
       "  1425258961,\n",
       "  3097643508,\n",
       "  3284273118,\n",
       "  1741134407,\n",
       "  2704855272,\n",
       "  1540627389,\n",
       "  619616543,\n",
       "  2912642492,\n",
       "  1407080303,\n",
       "  2147775548,\n",
       "  342144662,\n",
       "  605945498,\n",
       "  2604966694,\n",
       "  1169278445,\n",
       "  2806935214,\n",
       "  1845255361,\n",
       "  4253865105,\n",
       "  2424852492,\n",
       "  3220342852,\n",
       "  3044969604,\n",
       "  2369557791,\n",
       "  3944433835,\n",
       "  361830992,\n",
       "  1035563611,\n",
       "  2615902706,\n",
       "  63728513,\n",
       "  1206638331,\n",
       "  3914624941,\n",
       "  4092940365,\n",
       "  945455893,\n",
       "  1012752871,\n",
       "  1203138566,\n",
       "  2219758203,\n",
       "  2607478439,\n",
       "  1870915836,\n",
       "  656524122,\n",
       "  1519722235,\n",
       "  1472190558,\n",
       "  3789511494,\n",
       "  2433656999,\n",
       "  281388589,\n",
       "  3308571539,\n",
       "  3263592539,\n",
       "  1786240607,\n",
       "  4224256015,\n",
       "  3425782246,\n",
       "  491532461,\n",
       "  3327314958,\n",
       "  1197842248,\n",
       "  3597673526,\n",
       "  2618639745,\n",
       "  4088884280,\n",
       "  1160432962,\n",
       "  1268100894,\n",
       "  3705909285,\n",
       "  4190075642,\n",
       "  28434612,\n",
       "  1012249355,\n",
       "  3263570443,\n",
       "  415191985,\n",
       "  3272387443,\n",
       "  1432264075,\n",
       "  2335357395,\n",
       "  1108339909,\n",
       "  3466907165,\n",
       "  345508898,\n",
       "  4031649215,\n",
       "  2701575236,\n",
       "  4005765066,\n",
       "  2007641626,\n",
       "  4241474937,\n",
       "  2303861743,\n",
       "  1889572402,\n",
       "  1465110890,\n",
       "  830535807,\n",
       "  3952106625,\n",
       "  4143151008,\n",
       "  2723768957,\n",
       "  2745237955,\n",
       "  1219819620,\n",
       "  3982311347,\n",
       "  3518187788,\n",
       "  2993498252,\n",
       "  3437902923,\n",
       "  1563762808,\n",
       "  2452944658,\n",
       "  2234375980,\n",
       "  3234447096,\n",
       "  4293513471,\n",
       "  2929406273,\n",
       "  4241194027,\n",
       "  4015349956,\n",
       "  1411703584,\n",
       "  4275377473,\n",
       "  26312500,\n",
       "  3134138338,\n",
       "  3565110941,\n",
       "  2113488064,\n",
       "  1636459250,\n",
       "  3746346397,\n",
       "  3466409963,\n",
       "  1402066190,\n",
       "  2956579518,\n",
       "  3827521702,\n",
       "  4151874557,\n",
       "  1711525785,\n",
       "  915767561,\n",
       "  3913493129,\n",
       "  3951774585,\n",
       "  558840360,\n",
       "  690628074,\n",
       "  828882025,\n",
       "  1335032130,\n",
       "  752448887,\n",
       "  20593246,\n",
       "  2082486635,\n",
       "  802392447,\n",
       "  2474103637,\n",
       "  1495602943,\n",
       "  1532422125,\n",
       "  2487347299,\n",
       "  868525950,\n",
       "  2233962813,\n",
       "  1403455620,\n",
       "  1031978967,\n",
       "  2868752678,\n",
       "  1486193931,\n",
       "  303845392,\n",
       "  988314119,\n",
       "  84844661,\n",
       "  3154496937,\n",
       "  1489390983,\n",
       "  193911277,\n",
       "  3448014469,\n",
       "  3908436769,\n",
       "  2033563919,\n",
       "  100435662,\n",
       "  371201327,\n",
       "  710983475,\n",
       "  3363276777,\n",
       "  961627465,\n",
       "  3096022231,\n",
       "  860669133,\n",
       "  3826748848,\n",
       "  2230538095,\n",
       "  210539172,\n",
       "  3485565217,\n",
       "  3726370017,\n",
       "  3833428207,\n",
       "  3083384169,\n",
       "  3800456127,\n",
       "  2273133366,\n",
       "  1630966645,\n",
       "  2821455416,\n",
       "  3686794668,\n",
       "  1799939994,\n",
       "  2917504547,\n",
       "  2466704057,\n",
       "  159047418,\n",
       "  3363375575,\n",
       "  2569779799,\n",
       "  732068017,\n",
       "  2456367544,\n",
       "  2437598770,\n",
       "  1473971777,\n",
       "  3020698185,\n",
       "  3181221368,\n",
       "  1320033057,\n",
       "  807319681,\n",
       "  3999916364,\n",
       "  3784533456,\n",
       "  3016481812,\n",
       "  1728952878,\n",
       "  3462495511,\n",
       "  4107971288,\n",
       "  1827576708,\n",
       "  2839396082,\n",
       "  3269623662,\n",
       "  153874831,\n",
       "  3123149028,\n",
       "  433914078,\n",
       "  1053066471,\n",
       "  2295751286,\n",
       "  3458460144,\n",
       "  4250882346,\n",
       "  1084494029,\n",
       "  3621102479,\n",
       "  1515286323,\n",
       "  3696640937,\n",
       "  4043514309,\n",
       "  578426478,\n",
       "  2514795380,\n",
       "  2093282204,\n",
       "  694292530,\n",
       "  967901927,\n",
       "  2564448152,\n",
       "  1522539740,\n",
       "  491209467,\n",
       "  2562005632,\n",
       "  3584872868,\n",
       "  506455236,\n",
       "  2075256459,\n",
       "  3276494092,\n",
       "  3349482857,\n",
       "  2134237631,\n",
       "  2339875513,\n",
       "  103438161,\n",
       "  953970039,\n",
       "  3147399516,\n",
       "  3874075889,\n",
       "  3347221706,\n",
       "  3004297468,\n",
       "  2953888113,\n",
       "  789028919,\n",
       "  1134304584,\n",
       "  3842735942,\n",
       "  643633383,\n",
       "  2170464031,\n",
       "  1614349381,\n",
       "  556355643,\n",
       "  2619167109,\n",
       "  4144319579,\n",
       "  3864414227,\n",
       "  3691116509,\n",
       "  3038756639,\n",
       "  2233789804,\n",
       "  3328777024,\n",
       "  3351783997,\n",
       "  635469798,\n",
       "  1792891679,\n",
       "  2334034490,\n",
       "  2124782162,\n",
       "  3589471979,\n",
       "  69290401,\n",
       "  1910866721,\n",
       "  2574234339,\n",
       "  328857347,\n",
       "  1825368894,\n",
       "  1334178030,\n",
       "  2165797511,\n",
       "  3037287162,\n",
       "  1601569370,\n",
       "  3050705694,\n",
       "  746324322,\n",
       "  3908386470,\n",
       "  816601303,\n",
       "  2487336176,\n",
       "  1502297153,\n",
       "  2161660457,\n",
       "  2632097116,\n",
       "  2861652087,\n",
       "  3694339402,\n",
       "  259511204,\n",
       "  804227961,\n",
       "  3610593907,\n",
       "  2467647083,\n",
       "  476037119,\n",
       "  1331253252,\n",
       "  4156608388,\n",
       "  1861800672,\n",
       "  1439551538,\n",
       "  1265280807,\n",
       "  479854799,\n",
       "  3118642386,\n",
       "  1532342807,\n",
       "  3086993847,\n",
       "  2794328748,\n",
       "  2103320473,\n",
       "  127300152,\n",
       "  1373759329,\n",
       "  3939723547,\n",
       "  3746381792,\n",
       "  3411479215,\n",
       "  2559256594,\n",
       "  413307812,\n",
       "  2188857428,\n",
       "  646735130,\n",
       "  4116686623,\n",
       "  4011825597,\n",
       "  974749917,\n",
       "  3306586226,\n",
       "  649974412,\n",
       "  1011646780,\n",
       "  4147856088,\n",
       "  3098280017,\n",
       "  3596914250,\n",
       "  3274834315,\n",
       "  1778671820,\n",
       "  55914292,\n",
       "  1706994636,\n",
       "  950120524,\n",
       "  910325017,\n",
       "  261751567,\n",
       "  3917147568,\n",
       "  2312146585,\n",
       "  2844198593,\n",
       "  882162268,\n",
       "  3419049723,\n",
       "  1485122346,\n",
       "  2000897480,\n",
       "  1209594045,\n",
       "  2079501469,\n",
       "  1289720974,\n",
       "  2357597513,\n",
       "  1707293361,\n",
       "  1383589810,\n",
       "  3619517373,\n",
       "  4071836699,\n",
       "  3923988613,\n",
       "  3097674562,\n",
       "  2564357041,\n",
       "  89817526,\n",
       "  1173086938,\n",
       "  1027192136,\n",
       "  627876877,\n",
       "  1985762437,\n",
       "  64009317,\n",
       "  474197618,\n",
       "  330743137,\n",
       "  2886558402,\n",
       "  340490042,\n",
       "  2018946067,\n",
       "  2795551343,\n",
       "  1958306647,\n",
       "  3509015217,\n",
       "  543685451,\n",
       "  2548629143,\n",
       "  2051005264,\n",
       "  706113104,\n",
       "  2874170366,\n",
       "  3515629154,\n",
       "  2031987664,\n",
       "  1432507441,\n",
       "  3159177478,\n",
       "  3001513201,\n",
       "  210976715,\n",
       "  3765371406,\n",
       "  815792858,\n",
       "  1825864115,\n",
       "  2533831149,\n",
       "  2493980965,\n",
       "  4052559832,\n",
       "  754028307,\n",
       "  3574383684,\n",
       "  2446459154,\n",
       "  129708476,\n",
       "  2997116649,\n",
       "  2052155596,\n",
       "  2434212372,\n",
       "  1034846090,\n",
       "  389669362,\n",
       "  2227490222,\n",
       "  2653595951,\n",
       "  606988835,\n",
       "  1572874084,\n",
       "  2290329648,\n",
       "  4280282652,\n",
       "  2067664007,\n",
       "  1822457753,\n",
       "  1632306001,\n",
       "  1891559172,\n",
       "  1179306314,\n",
       "  3889644590,\n",
       "  2156097599,\n",
       "  1290667305,\n",
       "  2208510483,\n",
       "  618992923,\n",
       "  1067905201,\n",
       "  2283016081,\n",
       "  4222448818,\n",
       "  2857371123,\n",
       "  2689459426,\n",
       "  2445761606,\n",
       "  3984499468,\n",
       "  215469117,\n",
       "  2034329369,\n",
       "  1616747428,\n",
       "  193523874,\n",
       "  2148136389,\n",
       "  74739700,\n",
       "  4116671291,\n",
       "  1566302668,\n",
       "  1429500354,\n",
       "  1176253187,\n",
       "  1973218888,\n",
       "  4121961079,\n",
       "  2684820978,\n",
       "  3338323230,\n",
       "  3835426350,\n",
       "  79184022,\n",
       "  995189740,\n",
       "  3779281006,\n",
       "  3865016040,\n",
       "  3727844217,\n",
       "  2921503875,\n",
       "  689334478,\n",
       "  1057298460,\n",
       "  50139187,\n",
       "  1584776268,\n",
       "  573038140,\n",
       "  2856564515,\n",
       "  1115196860,\n",
       "  2879955873,\n",
       "  4044054978,\n",
       "  142795650,\n",
       "  3640476547,\n",
       "  273315689,\n",
       "  3356925308,\n",
       "  2150913395,\n",
       "  1503898597,\n",
       "  734274263,\n",
       "  3217973178,\n",
       "  352150135,\n",
       "  2283603860,\n",
       "  1449073677,\n",
       "  1954653839,\n",
       "  2397222458,\n",
       "  291558500,\n",
       "  2210321446,\n",
       "  4063462629,\n",
       "  2086478965,\n",
       "  1136025329,\n",
       "  381252457,\n",
       "  3136389747,\n",
       "  1433992423,\n",
       "  2500731391,\n",
       "  1517496294,\n",
       "  2374025624,\n",
       "  3474125747,\n",
       "  91787015,\n",
       "  1728291358,\n",
       "  271053643,\n",
       "  4169936178,\n",
       "  3101184200,\n",
       "  2283210856,\n",
       "  2116231906,\n",
       "  3793710311,\n",
       "  3021995804,\n",
       "  4229671399,\n",
       "  3408434012,\n",
       "  4181671547,\n",
       "  659728741,\n",
       "  3224621997,\n",
       "  3439613407,\n",
       "  3695567819,\n",
       "  3792061186,\n",
       "  714977695,\n",
       "  624),\n",
       " None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['rng'][0]['python']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MT19937',\n",
       " array([        17,  746594230, 3313428688,  930072130, 4093676046,\n",
       "        3497159718,  168261535, 1297041602,  797773815, 3824384892,\n",
       "         815771685,  289885092,  974625728, 3488232141, 2822261076,\n",
       "        3335386365, 2186253894, 3433868517, 3941682384, 4044700242,\n",
       "        1036802825,  127318946,  575650048, 1114963223,  120758214,\n",
       "        3571711799, 3958539166, 3026711052, 1408105890,  756436076,\n",
       "        1604711098,  310105830, 2032590558, 3316925724, 1895160925,\n",
       "        4201720943,  643846848, 4085868005, 1845971428, 4037981312,\n",
       "        2803651287,  911452978, 4227747044,  281867854, 4107201266,\n",
       "        1777642050, 2826569629,  261232874, 3126791810, 3418568881,\n",
       "        2184880236, 2348689817, 3334954331, 3406031853,  223376156,\n",
       "        1142646339,  743877186, 1595702851,  295510596, 2855332111,\n",
       "         761194333, 1070402798, 2857596964,  793034045, 1477398097,\n",
       "        3542267345, 1891442204, 3196413620,  630385682, 2143995231,\n",
       "        4231081052,  448682178, 2951141074, 2394427481, 2782668593,\n",
       "        3610952298, 4179092665, 3370829743, 4012888874,  134103164,\n",
       "        1261817148, 3485113954,  336160151, 1781785574, 1522567543,\n",
       "        1639997923, 2323026048, 3752498593, 4157520706, 4052527614,\n",
       "        4116870699, 2620130851, 1133319265,  892365373, 2292158319,\n",
       "         850389856,  335428928, 2664786593, 2394508721,  496333570,\n",
       "        2744152622, 2219481025, 2264546133, 2111568058,  285357359,\n",
       "         748561140,  532962990, 2649127185, 4131254251, 3140144885,\n",
       "        2640762593, 3334947582, 2690765633, 2877043936, 3933982620,\n",
       "        2253259054, 1402667728,  811660778, 1799438280, 3328162756,\n",
       "        2511574267, 1231161270, 3553557165, 2542929185, 3645948491,\n",
       "        2764910309, 2405310625, 2551126990, 3865715708, 1159506716,\n",
       "        2242709491,  974855064, 1335769980, 1940807126,  954471769,\n",
       "        2732068260, 1175795974, 2232762188, 2204416080, 1604229861,\n",
       "         112402560, 1687180045, 1052127306, 3351160769, 1145897498,\n",
       "        2604615736, 2402584948,  662987297,  178610329, 3827301874,\n",
       "        3172739499,  503767364, 1612727404,  206853274, 1187105628,\n",
       "        1809121612,  232175869,  698442094, 3687927556, 3658476898,\n",
       "        4160262373, 3638968671, 1700136430,   27672302, 3200660106,\n",
       "         385136717, 2336812039, 2318846880, 3288730002,    7823326,\n",
       "        1484300608, 1252681808, 2907013537, 3728826620, 3886857289,\n",
       "         904913889, 3485421941, 1531791935, 2448128296, 2648983621,\n",
       "        1672446903, 2746572163, 2686381467, 3297353492, 1041241035,\n",
       "        1165783760, 1396844079, 2999561953,   73300811, 1280231508,\n",
       "        2594015047,  476924920, 1754182040,   75887390, 3318086040,\n",
       "         820801002, 2373949462, 3024467113, 2178730813, 2275010466,\n",
       "        2987197160,   35086619, 1642972017, 2020936699, 4117529710,\n",
       "        2175374542,  169664842, 3539696897,  372008090,  965745555,\n",
       "        2577501393, 4007557906, 3608782729, 1687024711, 3651458676,\n",
       "         638536906, 2242340490, 2124561537, 1877106522, 1221874370,\n",
       "        3814982347, 2942968261, 3781415777, 2016401545, 1366898312,\n",
       "        1287706094,  672812845,  217797284,  282943384, 3701936093,\n",
       "        2356744572, 3633468829, 3235862078, 3035540474, 1878626754,\n",
       "        4241284570, 4235962505, 2646694239, 1671825311,  132550725,\n",
       "        2400114985, 2000728552, 3575309023, 2064072127, 1108871914,\n",
       "        1640043180, 1659237431, 2313437253, 1130650619, 1202132123,\n",
       "         925338556,  243645991, 4103595359, 3744447049, 3901495856,\n",
       "        4105216542, 3141303153,  554844256,  323405538, 1133079085,\n",
       "        2788978784, 1487587759, 1293004972, 2957134408, 1139731002,\n",
       "        4097375568, 3411172809,  339090365, 1817974685, 2117848473,\n",
       "        2378593798,  244364451, 3828842591,  270197085,  583053251,\n",
       "        3865687042, 3507457657,  733511991, 3111283401, 4107781678,\n",
       "        2037007833, 3476432721, 1722181236, 3048081988, 2702410938,\n",
       "        1069667765,  382348935, 1784388450,      84527, 2357095596,\n",
       "        1993080776, 3571285104, 1847633283, 1241636719, 3075540364,\n",
       "        3184668717, 2231315123, 3713765886,  271318779, 3383553330,\n",
       "        1149226625,  292485549,  337713007,  513910522, 2700651474,\n",
       "         146676289, 1389635031, 2261546145, 2374647939,   60259610,\n",
       "        3765257848, 3610354366, 2782354121, 3441063504, 1426594553,\n",
       "        1063869715, 4142261435, 1361163733, 1969697250, 2896046798,\n",
       "        4209119164, 4158025372, 2737159421, 1325467870,  188799039,\n",
       "        2718435616, 3523005872, 1186395110, 3993361003, 3809006673,\n",
       "        2992220068, 4120968137,  701002238,  117958787, 2703349757,\n",
       "         720023530,  237085346, 1572592955,  152589108, 3515590871,\n",
       "        2000621816, 1321596050, 3087084117,  343884970, 3399160426,\n",
       "        3102176710, 3115539374, 1367750711, 1333990570,  963881940,\n",
       "        3026403330,  141050207, 4189496027, 3592149145, 1142743076,\n",
       "         274414844, 1116073168, 2420721882, 1120753310, 2964800802,\n",
       "         808216328, 4125093777, 4253853700, 3667594030, 2187427629,\n",
       "        3956299256, 3306307701,  267163133, 3129381697, 3871077856,\n",
       "         468942593,  990881240, 1440024492,  266509750, 2731057220,\n",
       "        2161554197, 1412233355, 1250290155,  778667212, 2034668023,\n",
       "        1655586186, 2155523156, 1425671532, 1971747456,  455368549,\n",
       "        1680453978,  299478377, 2458754288, 4252659454, 1268658262,\n",
       "        2208867033,  145519854, 1361019246, 1002142036, 2788217774,\n",
       "         205426791, 3066501423, 1430324558, 3886506169,  350401777,\n",
       "         786259365,  536232106, 3781721764, 3297925238, 2789639357,\n",
       "        2350225392,  309556752,  204219879, 3942945979, 3714917937,\n",
       "        3906917716, 2843130862,  433942968, 1916884789, 1574845730,\n",
       "        1734007662,  978320235, 3540481496, 3707810825, 3051774869,\n",
       "        2085755703, 2205066227,  939108539,  837330542,  651987214,\n",
       "          29135407, 1827263797, 3754292015, 1852800520, 2058259514,\n",
       "        2307254261, 1991816482, 1740911487, 2154348647, 2534209163,\n",
       "         298555072,  406797172, 4159670905, 1139994072, 3708811604,\n",
       "        1226698763, 2794131371, 3655180391,  570543407, 3519880263,\n",
       "        4293430417, 3656882520,  356398502,  734724670,  587010615,\n",
       "        4028145781,  315651665, 1673988281, 3191401053, 4269428801,\n",
       "        3842178513, 2093057954, 1130741784, 3617664167, 3153486463,\n",
       "        1884602909, 3423965913,  202349520,  523946719, 1759273675,\n",
       "         995562883, 3732117889, 2874156061, 2328615183, 1156552950,\n",
       "        3458501193, 3799132937, 3579401930,  657444902, 3310057176,\n",
       "        3713931586, 3463102849, 3023760423, 3030514039,  546966024,\n",
       "        4066131720, 1500431416, 4182043999, 2294014767, 2968434597,\n",
       "         134731208, 2499240398, 3850617699, 3895097032,  903906048,\n",
       "        4239306986, 1341619928,   58076809, 2923867898, 4266508742,\n",
       "        1505943976,  742750877, 1012033250,  230656796, 2345132031,\n",
       "        4171548101,  927137555, 2775895925, 2858257130, 4069914496,\n",
       "        4281648040, 1781839729, 1627869483,  578322830, 2311200003,\n",
       "        1914829923, 1982269097, 2391640648, 4242484019, 2692266994,\n",
       "        1338349491, 1963007294,  584073952, 2215920742,   55869819,\n",
       "        4160678543, 3169548101, 3266056205,  987485585, 3774668097,\n",
       "        4210663191, 1680439538, 2294007022, 1626013484, 4118856658,\n",
       "        1263475847, 1545861361, 2834933956, 1799065139,  687201744,\n",
       "        2372195623,  786163377,  638435054, 4280005632, 2841158218,\n",
       "         248025220, 3457395249, 2469718488, 3254513441, 1028426890,\n",
       "         909069971, 3686509857,  882934413, 3071015109, 1632413608,\n",
       "        1251383507, 3404771073, 2141921266, 1447143432, 2400394935,\n",
       "        3773627540,  751663295, 2213010568, 1598414496, 4246470836,\n",
       "         292501859, 3159138624, 2371220284, 2428970921, 3967429547,\n",
       "        3207078781, 1917712977, 1810404295, 2621523286, 3911602269,\n",
       "        1471284560,  793474096, 2000849196, 1692677630, 4243048153,\n",
       "         953294913,  737182949, 1262878106, 2056389481, 2001076811,\n",
       "        3453911926, 1096186990, 1254064401, 1091534231, 2892747894,\n",
       "        2053695501, 3622173446,  976533572, 3880065312, 2896930844,\n",
       "        1032021028, 2187970691, 4153419317, 2748054431, 3865857091,\n",
       "        4081604499, 3612778020,  383796920, 2606522606, 4056189811,\n",
       "        2704930184, 2399845323,  473541031,  370888766, 2959726802,\n",
       "        3967409261, 4060927940,  956015330, 4053809034, 1655520366,\n",
       "         515457325,  120770084, 3663239832,  770634892, 3220793762,\n",
       "        2588757639, 2166893025, 1551369208, 3712537767, 1208199967,\n",
       "        3050804034,  580541101, 3089587631, 1147440304], dtype=uint32),\n",
       " 624,\n",
       " 0,\n",
       " 0.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['rng'][0]['numpy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 17,   0,   0,   0,   0,   0,   0,   0, 192,  79,   4,   0,   0,   0,\n",
       "          0,   0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['rng'][0]['cuda']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing `amazon/chronos-t5-small`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in `google-t5/t5-small`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.t5.tokenization_t5_fast.T5TokenizerFast"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('google-t5/t5-small')\n",
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.t5.tokenization_t5_fast.T5TokenizerFast"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = T5TokenizerFast.from_pretrained('google-t5/t5-small')\n",
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "transformers.models.t5.tokenization_t5.T5Tokenizer"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('google-t5/t5-small')\n",
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'T5Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_fast.PreTrainedTokenizerFast"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('google-t5/t5-small')\n",
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "{'input_ids': [101, 7592, 1010, 2129, 2024, 2017, 1029, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load a pre-trained tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize a single sentence\n",
    "encoded_input = tokenizer(\"Hello, how are you?\")\n",
    "print(type(encoded_input))\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.tokenization_utils_base.BatchEncoding'>\n",
      "{'input_ids': tensor([[ 101, 7592, 1010, 2129, 2024, 2017, 1029,  102,    0],\n",
      "        [ 101, 1045, 2572, 2986, 1010, 4067, 2017, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "tensor([[ 101, 7592, 1010, 2129, 2024, 2017, 1029,  102,    0],\n",
      "        [ 101, 1045, 2572, 2986, 1010, 4067, 2017, 1012,  102]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize a batch of sentences\n",
    "batch_sentences = [\"Hello, how are you?\", \"I am fine, thank you.\"]\n",
    "batch_encoded_input = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Accessing BatchEncoding properties\n",
    "input_ids = batch_encoded_input[\"input_ids\"]\n",
    "attention_mask = batch_encoded_input[\"attention_mask\"]\n",
    "\n",
    "print(type(batch_encoded_input))\n",
    "print(batch_encoded_input)\n",
    "print(input_ids)\n",
    "print(attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorrectly loading in `amazon/chronos-t5-small`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't load tokenizer for 'amazon/chronos-t5-small'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'amazon/chronos-t5-small' is the correct path to a directory containing all relevant files for a T5TokenizerFast tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamazon/chronos-t5-small\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:880\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m tokenizer_class_py, tokenizer_class_fast \u001b[38;5;241m=\u001b[39m TOKENIZER_MAPPING[\u001b[38;5;28mtype\u001b[39m(config)]\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_fast \u001b[38;5;129;01mand\u001b[39;00m (use_fast \u001b[38;5;129;01mor\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 880\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class_fast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    882\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2073\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2067\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   2068\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load following files from cache: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munresolved_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and cannot check if these \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2069\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles are necessary for the tokenizer to operate.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2070\u001b[0m     )\n\u001b[1;32m   2072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(full_file_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m full_file_name \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m-> 2073\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   2074\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load tokenizer for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2075\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same name. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2076\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2077\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontaining all relevant files for a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2078\u001b[0m     )\n\u001b[1;32m   2080\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_id, file_path \u001b[38;5;129;01min\u001b[39;00m vocab_files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   2081\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files:\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'amazon/chronos-t5-small'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'amazon/chronos-t5-small' is the correct path to a directory containing all relevant files for a T5TokenizerFast tokenizer."
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"amazon/chronos-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't load tokenizer for 'amazon/chronos-t5-small'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'amazon/chronos-t5-small' is the correct path to a directory containing all relevant files for a T5TokenizerFast tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mT5TokenizerFast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamazon/chronos-t5-small\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2073\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2067\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   2068\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load following files from cache: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munresolved_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and cannot check if these \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2069\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles are necessary for the tokenizer to operate.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2070\u001b[0m     )\n\u001b[1;32m   2072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(full_file_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m full_file_name \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m-> 2073\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   2074\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load tokenizer for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2075\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same name. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2076\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2077\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontaining all relevant files for a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2078\u001b[0m     )\n\u001b[1;32m   2080\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_id, file_path \u001b[38;5;129;01min\u001b[39;00m vocab_files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   2081\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files:\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'amazon/chronos-t5-small'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'amazon/chronos-t5-small' is the correct path to a directory containing all relevant files for a T5TokenizerFast tokenizer."
     ]
    }
   ],
   "source": [
    "tokenizer = T5TokenizerFast.from_pretrained(\"amazon/chronos-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't load tokenizer for 'amazon/chronos-t5-small'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'amazon/chronos-t5-small' is the correct path to a directory containing all relevant files for a T5Tokenizer tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mT5Tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamazon/chronos-t5-small\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2073\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2067\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   2068\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load following files from cache: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munresolved_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and cannot check if these \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2069\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles are necessary for the tokenizer to operate.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2070\u001b[0m     )\n\u001b[1;32m   2072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(full_file_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m full_file_name \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m-> 2073\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   2074\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load tokenizer for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2075\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same name. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2076\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2077\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontaining all relevant files for a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2078\u001b[0m     )\n\u001b[1;32m   2080\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_id, file_path \u001b[38;5;129;01min\u001b[39;00m vocab_files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   2081\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files:\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'amazon/chronos-t5-small'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'amazon/chronos-t5-small' is the correct path to a directory containing all relevant files for a T5Tokenizer tokenizer."
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"amazon/chronos-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't load tokenizer for 'amazon/chronos-t5-small'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'amazon/chronos-t5-small' is the correct path to a directory containing all relevant files for a PreTrainedTokenizerFast tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mPreTrainedTokenizerFast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamazon/chronos-t5-small\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2073\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2067\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   2068\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load following files from cache: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munresolved_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and cannot check if these \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2069\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles are necessary for the tokenizer to operate.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2070\u001b[0m     )\n\u001b[1;32m   2072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(full_file_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m full_file_name \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m-> 2073\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   2074\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load tokenizer for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2075\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same name. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2076\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2077\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontaining all relevant files for a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2078\u001b[0m     )\n\u001b[1;32m   2080\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_id, file_path \u001b[38;5;129;01min\u001b[39;00m vocab_files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   2081\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files:\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'amazon/chronos-t5-small'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'amazon/chronos-t5-small' is the correct path to a directory containing all relevant files for a PreTrainedTokenizerFast tokenizer."
     ]
    }
   ],
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"amazon/chronos-t5-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correctly loading in `amazon/chronos-t5-small`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.t5.configuration_t5.T5Config'>\n",
      "<class 'chronos.chronos.ChronosConfig'>\n",
      "<class 'chronos.chronos.MeanScaleUniformBins'>\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained('amazon/chronos-t5-small')\n",
    "print(type(config))\n",
    "\n",
    "chronos_config = ChronosConfig(**config.chronos_config)\n",
    "print(type(chronos_config))\n",
    "\n",
    "tokenizer = chronos_config.create_tokenizer()\n",
    "print(type(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.t5.tokenization_t5_fast.T5TokenizerFast'>\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained('amazon/chronos-t5-small')\n",
    "tokenizer = AutoTokenizer.from_pretrained('google-t5/t5-small')\n",
    "print(type(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test out `ChronosPipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken straight from chronos-forecasting/src/chronos/chronos.py\n",
    "\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Literal, Optional, Tuple, Union\n",
    "\n",
    "# import chronos\n",
    "import chronos.chronos as chronos\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    GenerationConfig,\n",
    "    PreTrainedModel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ChronosPipeline:\n",
    "    \"\"\"\n",
    "    A ``ChronosPipeline`` uses the given tokenizer and model to forecast input time series. Use the ``from_pretrained`` class method to load serialized models. Use the ``predict`` method to get forecasts.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tokenizer\n",
    "        The tokenizer object to use.\n",
    "    model\n",
    "        The model to use.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: ChronosTokenizer\n",
    "    model: ChronosModel\n",
    "\n",
    "    def _prepare_and_validate_context(\n",
    "        self, context: Union[torch.Tensor, List[torch.Tensor]]\n",
    "    ):\n",
    "        if isinstance(context, list):\n",
    "            context = left_pad_and_stack_1D(context)\n",
    "        assert isinstance(context, torch.Tensor)\n",
    "        if context.ndim == 1:\n",
    "            context = context.unsqueeze(0)\n",
    "        assert context.ndim == 2\n",
    "\n",
    "        return context\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def embed(\n",
    "        self, context: Union[torch.Tensor, List[torch.Tensor]]\n",
    "    ) -> Tuple[torch.Tensor, Any]:\n",
    "        \"\"\"\n",
    "        Get encoder embeddings for the given time series.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        context\n",
    "            Input series. This is either a 1D tensor, or a list of 1D tensors, or a 2D tensor whose first dimension is batch. In the latter case, use left-padding with ``torch.nan`` to align series of different lengths.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        embeddings, tokenizer_state\n",
    "            A tuple of two tensors: the encoder embeddings and the tokenizer_state, e.g., the scale of the time series in the case of mean scaling. The encoder embeddings are shaped (batch_size, context_length, d_model) or (batch_size, context_length + 1, d_model), \n",
    "            where context_length is the size of the context along the time axis if a 2D tensor was provided or the length of the longest time series, if a list of 1D tensors was provided, and the extra 1 is for EOS.\n",
    "        \"\"\"\n",
    "        context_tensor = self._prepare_and_validate_context(context=context)\n",
    "        token_ids, attention_mask, tokenizer_state = (\n",
    "            self.tokenizer.context_input_transform(context_tensor)\n",
    "        )\n",
    "        embeddings = self.model.encode(\n",
    "            input_ids=token_ids.to(self.model.device),\n",
    "            attention_mask=attention_mask.to(self.model.device),\n",
    "        ).cpu()\n",
    "        return embeddings, tokenizer_state\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        context: Union[torch.Tensor, List[torch.Tensor]],\n",
    "        prediction_length: Optional[int] = None,\n",
    "        num_samples: Optional[int] = None,\n",
    "        temperature: Optional[float] = None,\n",
    "        top_k: Optional[int] = None,\n",
    "        top_p: Optional[float] = None,\n",
    "        limit_prediction_length: bool = True,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Get forecasts for the given time series.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        context\n",
    "            Input series. This is either a 1D tensor, or a list of 1D tensors, or a 2D tensor whose first dimension is batch. In the latter case, use left-padding with ``torch.nan`` to align series of different lengths.\n",
    "        prediction_length\n",
    "            Time steps to predict. Defaults to what specified in ``self.model.config``.\n",
    "        num_samples\n",
    "            Number of sample paths to predict. Defaults to what specified in ``self.model.config``.\n",
    "        temperature\n",
    "            Temperature to use for generating sample tokens. Defaults to what specified in ``self.model.config``.\n",
    "        top_k\n",
    "            Top-k parameter to use for generating sample tokens. Defaults to what specified in ``self.model.config``.\n",
    "        top_p\n",
    "            Top-p parameter to use for generating sample tokens. Defaults to what specified in ``self.model.config``.\n",
    "        limit_prediction_length\n",
    "            Force prediction length smaller or equal than the built-in prediction length from the model. True by default. When true, fail loudly if longer predictions are requested, otherwise longer predictions are allowed.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        samples\n",
    "            Tensor of sample forecasts, of shape (batch_size, num_samples, prediction_length).\n",
    "        \"\"\"\n",
    "        context_tensor = self._prepare_and_validate_context(context=context)\n",
    "\n",
    "        if prediction_length is None:\n",
    "            prediction_length = self.model.config.prediction_length\n",
    "\n",
    "        if prediction_length > self.model.config.prediction_length:\n",
    "            msg = (\n",
    "                f\"We recommend keeping prediction length <= {self.model.config.prediction_length}. \"\n",
    "                \"The quality of longer predictions may degrade since the model is not optimized for it. \"\n",
    "            )\n",
    "            if limit_prediction_length:\n",
    "                msg += \"You can turn off this check by setting `limit_prediction_length=False`.\"\n",
    "                raise ValueError(msg)\n",
    "            warnings.warn(msg)\n",
    "\n",
    "        predictions = []\n",
    "        remaining = prediction_length\n",
    "\n",
    "        while remaining > 0:\n",
    "            token_ids, attention_mask, scale = self.tokenizer.context_input_transform(\n",
    "                context_tensor\n",
    "            )\n",
    "            samples = self.model(\n",
    "                token_ids.to(self.model.device),\n",
    "                attention_mask.to(self.model.device),\n",
    "                min(remaining, self.model.config.prediction_length),\n",
    "                num_samples,\n",
    "                temperature,\n",
    "                top_k,\n",
    "                top_p,\n",
    "            )\n",
    "            prediction = self.tokenizer.output_transform(\n",
    "                samples.to(scale.device), scale\n",
    "            )\n",
    "\n",
    "            predictions.append(prediction)\n",
    "            remaining -= prediction.shape[-1]\n",
    "\n",
    "            if remaining <= 0:\n",
    "                break\n",
    "\n",
    "            context_tensor = torch.cat(\n",
    "                [context_tensor, prediction.median(dim=1).values], dim=-1\n",
    "            )\n",
    "\n",
    "        return torch.cat(predictions, dim=-1)\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Load the model, either from a local path or from the HuggingFace Hub. Supports the same arguments as ``AutoConfig`` and ``AutoModel`` from ``transformers``.\n",
    "        \"\"\"\n",
    "\n",
    "        config = AutoConfig.from_pretrained(*args, **kwargs)\n",
    "        print(f'type(config) == {type(config)}')\n",
    "\n",
    "        assert hasattr(config, \"chronos_config\"), \"Not a Chronos config file\"\n",
    "\n",
    "        chronos_config = ChronosConfig(**config.chronos_config)\n",
    "        print(f'type(chronos_config) == {type(chronos_config)}')\n",
    "\n",
    "        if chronos_config.model_type == \"seq2seq\":\n",
    "            inner_model = AutoModelForSeq2SeqLM.from_pretrained(*args, **kwargs)\n",
    "        else:\n",
    "            assert config.model_type == \"causal\"\n",
    "            inner_model = AutoModelForCausalLM.from_pretrained(*args, **kwargs)\n",
    "\n",
    "        # ADDED THIS LINE\n",
    "        tokenizer = chronos_config.create_tokenizer()\n",
    "        print(f'type(tokenizer) == {type(tokenizer)}')\n",
    "        \n",
    "        print(cls, type(cls))\n",
    "        print(args)\n",
    "        print(kwargs)\n",
    "        \n",
    "        return cls(\n",
    "            tokenizer=tokenizer, # original: chronos_config.create_tokenizer()\n",
    "            model=ChronosModel(config=chronos_config, model=inner_model),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(config) == <class 'transformers.models.t5.configuration_t5.T5Config'>\n",
      "type(chronos_config) == <class 'chronos.chronos.ChronosConfig'>\n",
      "type(tokenizer) == <class 'chronos.chronos.MeanScaleUniformBins'>\n",
      "<class '__main__.ChronosPipeline'> <class 'type'>\n",
      "('amazon/chronos-t5-small',)\n",
      "{'device_map': 'cpu', 'torch_dtype': torch.bfloat16}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "__main__.ChronosPipeline"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-small\",\n",
    "    device_map=\"cpu\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "type(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't load tokenizer for 'amazon/chronos-t5-small'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'amazon/chronos-t5-small' is the correct path to a directory containing all relevant files for a T5TokenizerFast tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamazon/chronos-t5-small\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16,\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 6\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mT5TokenizerFast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname_or_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/workdisk/kushal/llm-foundry/llmfoundry-venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2073\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2067\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   2068\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load following files from cache: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munresolved_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and cannot check if these \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2069\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles are necessary for the tokenizer to operate.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2070\u001b[0m     )\n\u001b[1;32m   2072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(full_file_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m full_file_name \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m-> 2073\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   2074\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load tokenizer for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2075\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same name. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2076\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2077\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontaining all relevant files for a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2078\u001b[0m     )\n\u001b[1;32m   2080\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_id, file_path \u001b[38;5;129;01min\u001b[39;00m vocab_files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   2081\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files:\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'amazon/chronos-t5-small'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'amazon/chronos-t5-small' is the correct path to a directory containing all relevant files for a T5TokenizerFast tokenizer."
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "    \"amazon/chronos-t5-small\",\n",
    "    device_map=\"cpu\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "tokenizer = T5TokenizerFast.from_pretrained(config.name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconfig\u001b[49m\u001b[38;5;241m.\u001b[39mname_or_path\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "config.name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
